# llama.cpp server settings
LLAMA_CPP_BASE_URL=http://localhost:8080/v1
LLAMA_CPP_EMBED_BASE_URL=http://localhost:8081/v1
LLAMA_CPP_MODEL=default
LLAMA_CPP_EMBED_MODEL=default
LLAMA_CPP_API_KEY=no-key

# Elasticsearch
ELASTICSEARCH_URL=http://localhost:9200
ELASTICSEARCH_INDEX=rag-documents

# Retrieval (RRF scores are rank-based, not cosine; 0.0 disables filtering)
RETRIEVAL_SCORE_THRESHOLD=0.0

# Docling (PDF parsing)
DOCLING_OCR_ENABLED=true
DOCLING_TABLE_MODE=accurate
DOCLING_TIMEOUT=120

# Langfuse observability (https://langfuse.com)
LANGFUSE_PUBLIC_KEY=pk-lf-...
LANGFUSE_SECRET_KEY=sk-lf-...
LANGFUSE_HOST=https://cloud.langfuse.com
LANGFUSE_ENABLED=true

# Redis (conversation session storage)
REDIS_URL=redis://localhost:6379/0

# LLM timeout (seconds)
LLM_TIMEOUT=120

