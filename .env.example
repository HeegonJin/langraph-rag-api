# llama.cpp server settings
LLAMA_CPP_BASE_URL=http://localhost:8080/v1
LLAMA_CPP_EMBED_BASE_URL=http://localhost:8081/v1
LLAMA_CPP_MODEL=default
LLAMA_CPP_EMBED_MODEL=default
LLAMA_CPP_API_KEY=no-key

# ChromaDB
CHROMA_PERSIST_DIR=./chroma_data

# Chunking
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Langfuse observability (https://langfuse.com)
LANGFUSE_PUBLIC_KEY=pk-lf-...
LANGFUSE_SECRET_KEY=sk-lf-...
LANGFUSE_HOST=https://cloud.langfuse.com
LANGFUSE_ENABLED=true

# Redis (conversation session storage)
REDIS_URL=redis://localhost:6379/0

# LLM timeout (seconds)
LLM_TIMEOUT=120
